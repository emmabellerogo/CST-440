// Auto-generated configuration for keyword detection
// Generated by 03_convert_model.py

#ifndef MODEL_CONFIG_H
#define MODEL_CONFIG_H

// Audio parameters
#define SAMPLE_RATE 16000
#define AUDIO_LENGTH_SAMPLES 16000

// MFCC parameters - MUST MATCH TRAINING!
#define NUM_MFCC 13
#define FRAME_LENGTH 640
#define FRAME_STEP 320
#define FFT_LENGTH 1024
#define NUM_FRAMES 49
#define NUM_MEL_BINS 40
#define LOWER_FREQ 20.0f
#define UPPER_FREQ 8000.0f

// Model parameters
#define NUM_CLASSES 8

// Class names
const char* const CLASS_NAMES[] = {
  "stop",
  "left",
  "right",
  "three",
  "cat",
  "bird",
  "_silence_",
  "_unknown_",
};

// Normalization statistics (from training data)
const float NORM_MEAN[] = {
  -11.190572f, 0.910320f, -0.052983f, 0.361194f, -0.341312f, 0.081729f, -0.393825f, -0.001923f, -0.144574f, 0.090732f, -0.256644f, 0.011929f, -0.265446f
};

const float NORM_STD[] = {
  22.005913f, 4.483224f, 2.316254f, 1.811167f, 1.435974f, 1.255059f, 1.174719f, 1.016554f, 0.894545f, 0.803193f, 0.771283f, 0.683892f, 0.669130f
};

#endif // MODEL_CONFIG_H
