"""
Step 4: Convert Model for Arduino Deployment
Converts Keras model to TensorFlow Lite with int8 quantization
and generates C header file for embedding in Arduino code.
"""

import os
import numpy as np
import tensorflow as tf

# ============================================================
# CONFIGURATION
# ============================================================

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(SCRIPT_DIR, "data", "processed")
MODEL_DIR = os.path.join(SCRIPT_DIR, "models")

# ============================================================
# CONVERT TO TFLITE
# ============================================================

def convert_to_tflite(model_path, X_train):
    """Convert Keras model to TFLite with int8 quantization."""

    print("Loading Keras model...")
    model = tf.keras.models.load_model(model_path)

    # Create TFLite converter
    converter = tf.lite.TFLiteConverter.from_keras_model(model)

    # Enable int8 quantization for smaller size and faster inference
    converter.optimizations = [tf.lite.Optimize.DEFAULT]

    # Representative dataset for quantization calibration
    def representative_dataset():
        for i in range(min(1000, len(X_train))):
            sample = X_train[i:i+1].astype(np.float32)
            yield [sample]

    converter.representative_dataset = representative_dataset

    # Force full int8 quantization (input/output stay float32 for compatibility)
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    converter.inference_input_type = tf.float32  # Keep float input for easier use
    converter.inference_output_type = tf.float32  # Keep float output

    print("Converting to TFLite with int8 quantization...")
    tflite_model = converter.convert()

    return tflite_model

def save_tflite_model(tflite_model, output_path):
    """Save TFLite model to file."""
    with open(output_path, 'wb') as f:
        f.write(tflite_model)

    size_kb = len(tflite_model) / 1024
    print(f"TFLite model saved: {output_path}")
    print(f"Model size: {size_kb:.1f} KB")

    return size_kb

# ============================================================
# GENERATE C HEADER FILE
# ============================================================

def generate_c_header(tflite_model, output_path, model_name="keyword_model"):
    """Generate C header file with model data for Arduino."""

    print(f"\nGenerating C header file...")

    with open(output_path, 'w') as f:
        f.write(f"// Auto-generated TensorFlow Lite model\n")
        f.write(f"// Model size: {len(tflite_model)} bytes\n")
        f.write(f"// Generated by 03_convert_model.py\n\n")

        f.write(f"#ifndef {model_name.upper()}_H\n")
        f.write(f"#define {model_name.upper()}_H\n\n")

        f.write(f"const unsigned int {model_name}_len = {len(tflite_model)};\n\n")

        f.write(f"alignas(8) const unsigned char {model_name}_data[] = {{\n")

        # Write bytes in rows of 12
        for i in range(0, len(tflite_model), 12):
            row = tflite_model[i:i+12]
            hex_values = ', '.join(f'0x{b:02x}' for b in row)
            f.write(f"  {hex_values},\n")

        f.write(f"}};\n\n")
        f.write(f"#endif // {model_name.upper()}_H\n")

    print(f"C header saved: {output_path}")

# ============================================================
# GENERATE ARDUINO CONFIG HEADER
# ============================================================

def generate_config_header(output_path, classes):
    """Generate configuration header with model parameters."""

    # Load MFCC parameters
    params = {}
    params_file = os.path.join(DATA_DIR, "mfcc_params.txt")
    with open(params_file, 'r') as f:
        for line in f:
            if '=' in line and not line.startswith('#'):
                key, value = line.strip().split('=', 1)
                params[key] = value

    # Load normalization stats
    norm_mean = np.load(os.path.join(DATA_DIR, "norm_mean.npy"))
    norm_std = np.load(os.path.join(DATA_DIR, "norm_std.npy"))

    with open(output_path, 'w') as f:
        f.write("// Auto-generated configuration for keyword detection\n")
        f.write("// Generated by 03_convert_model.py\n\n")

        f.write("#ifndef MODEL_CONFIG_H\n")
        f.write("#define MODEL_CONFIG_H\n\n")

        # Audio parameters
        f.write("// Audio parameters\n")
        f.write(f"#define SAMPLE_RATE {params['SAMPLE_RATE']}\n")
        f.write(f"#define AUDIO_LENGTH_SAMPLES {params['AUDIO_LENGTH_SAMPLES']}\n\n")

        # MFCC parameters
        f.write("// MFCC parameters - MUST MATCH TRAINING!\n")
        f.write(f"#define NUM_MFCC {params['NUM_MFCC']}\n")
        f.write(f"#define FRAME_LENGTH {params['FRAME_LENGTH']}\n")
        f.write(f"#define FRAME_STEP {params['FRAME_STEP']}\n")
        f.write(f"#define FFT_LENGTH {params['FFT_LENGTH']}\n")
        f.write(f"#define NUM_FRAMES {params['NUM_FRAMES']}\n")
        f.write(f"#define NUM_MEL_BINS {params['NUM_MEL_BINS']}\n")
        f.write(f"#define LOWER_FREQ {params['LOWER_FREQ']}f\n")
        f.write(f"#define UPPER_FREQ {params['UPPER_FREQ']}f\n\n")

        # Model parameters
        f.write("// Model parameters\n")
        f.write(f"#define NUM_CLASSES {len(classes)}\n\n")

        # Class names
        f.write("// Class names\n")
        f.write("const char* const CLASS_NAMES[] = {\n")
        for cls in classes:
            f.write(f'  "{cls}",\n')
        f.write("};\n\n")

        # Normalization stats
        f.write("// Normalization statistics (from training data)\n")
        f.write("const float NORM_MEAN[] = {\n  ")
        f.write(", ".join(f"{v:.6f}f" for v in norm_mean))
        f.write("\n};\n\n")

        f.write("const float NORM_STD[] = {\n  ")
        f.write(", ".join(f"{v:.6f}f" for v in norm_std))
        f.write("\n};\n\n")

        f.write("#endif // MODEL_CONFIG_H\n")

    print(f"Config header saved: {output_path}")

# ============================================================
# VERIFY TFLITE MODEL
# ============================================================

def verify_tflite_model(tflite_path, X_test, y_test, classes):
    """Verify the TFLite model produces correct predictions."""

    print("\nVerifying TFLite model accuracy...")

    # Load TFLite model
    interpreter = tf.lite.Interpreter(model_path=tflite_path)
    interpreter.allocate_tensors()

    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()

    print(f"  Input shape: {input_details[0]['shape']}")
    print(f"  Input dtype: {input_details[0]['dtype']}")
    print(f"  Output shape: {output_details[0]['shape']}")

    # Run inference on test samples
    num_samples = min(500, len(X_test))
    correct = 0

    for i in range(num_samples):
        sample = X_test[i:i+1].astype(np.float32)
        interpreter.set_tensor(input_details[0]['index'], sample)
        interpreter.invoke()
        output = interpreter.get_tensor(output_details[0]['index'])
        pred = np.argmax(output[0])

        if pred == y_test[i]:
            correct += 1

    accuracy = correct / num_samples
    print(f"\nTFLite model accuracy: {accuracy*100:.2f}% (on {num_samples} samples)")

    if accuracy < 0.85:
        print("WARNING: TFLite accuracy significantly lower than Keras model!")
        print("This may indicate quantization issues.")
    else:
        print("TFLite model verification passed!")

    return accuracy

# ============================================================
# MAIN
# ============================================================

if __name__ == "__main__":
    print("="*60)
    print("STEP 4: Converting Model for Arduino Deployment")
    print("="*60)

    # Check files exist
    keras_model_path = os.path.join(MODEL_DIR, "keyword_model.keras")
    if not os.path.exists(keras_model_path):
        print(f"\nERROR: Model not found at {keras_model_path}")
        print("Please run 02_train_model.py first.")
        exit(1)

    # Load training data for quantization calibration
    print("\nLoading data for quantization calibration...")
    X_train = np.load(os.path.join(DATA_DIR, "X_train.npy"))
    X_test = np.load(os.path.join(DATA_DIR, "X_test.npy"))
    y_test = np.load(os.path.join(DATA_DIR, "y_test.npy"))

    with open(os.path.join(DATA_DIR, "classes.txt"), 'r') as f:
        classes = [line.strip() for line in f.readlines()]

    print(f"  Classes: {classes}")

    # Convert to TFLite
    print("\n" + "="*50)
    tflite_model = convert_to_tflite(keras_model_path, X_train)

    # Save TFLite model
    tflite_path = os.path.join(MODEL_DIR, "keyword_model.tflite")
    model_size = save_tflite_model(tflite_model, tflite_path)

    # Check size for Arduino
    if model_size > 200:
        print(f"\nWARNING: Model size ({model_size:.1f} KB) may be too large for some Arduinos")
        print("Consider reducing model complexity if deployment fails.")
    else:
        print(f"\nModel size ({model_size:.1f} KB) is suitable for Arduino deployment!")

    # Generate C header files
    print("\n" + "="*50)
    print("Generating Arduino header files...")
    print("="*50)

    c_header_path = os.path.join(MODEL_DIR, "keyword_model_data.h")
    generate_c_header(tflite_model, c_header_path)

    config_header_path = os.path.join(MODEL_DIR, "model_config.h")
    generate_config_header(config_header_path, classes)

    # Verify TFLite model
    print("\n" + "="*50)
    verify_tflite_model(tflite_path, X_test, y_test, classes)

    print("\n" + "="*60)
    print("Conversion complete!")
    print("="*60)
    print("\nGenerated files:")
    print(f"  1. {tflite_path}")
    print(f"  2. {c_header_path}")
    print(f"  3. {config_header_path}")
    print("\nNext: Copy header files to Arduino project and run 04_create_arduino.py")
